{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEuRnMI8MuOE",
        "outputId": "624a8f1f-8327-4605-ca12-5fedeada8a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-20 07:12:34--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 245259777 (234M) [application/zip]\n",
            "Saving to: ‘concrete_crack_images.zip’\n",
            "\n",
            "concrete_crack_imag 100%[===================>] 233.90M  22.6MB/s    in 10s     \n",
            "\n",
            "2025-02-20 07:12:45 (23.3 MB/s) - ‘concrete_crack_images.zip’ saved [245259777/245259777]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O concrete_crack_images.zip \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /resources/data\n",
        "\n"
      ],
      "metadata": {
        "id": "QbZJ7x-EM8YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q concrete_crack_images.zip -d /resources/data/\n",
        "\n"
      ],
      "metadata": {
        "id": "GSaX1esgOO7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/resources/data/\"\n",
        "\n",
        "# Check folder structure (adjust paths if needed)\n",
        "print(\"Dataset contents:\", os.listdir(dataset_path))\n",
        "\n",
        "# Define transformations (resizing, converting to tensors, normalization)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Split dataset into training & validation sets (80% training, 20% validation)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"✅ Dataset loaded into PyTorch successfully!\")\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdN_Vtc1Oxb4",
        "outputId": "e049ec95-4b0a-4e57-c36b-279e7ff7aa34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contents: ['Negative', 'Positive']\n",
            "✅ Dataset loaded into PyTorch successfully!\n",
            "Training samples: 32000, Validation samples: 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final layer to match our two classes (Positive/Negative)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Binary classification\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the modified model structure\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRvIUP7_O7Qy",
        "outputId": "123e3703-239e-4839-ab87-0cb001418e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 133MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer (only update the final layer)\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function and optimizer initialized!\")\n"
      ],
      "metadata": {
        "id": "m5W3x2QKPFxs",
        "outputId": "20236a67-d2cc-45d9-d351-ab0301d3cfc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loss function and optimizer initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "id": "iLXTAnBAPKuk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f6431516-d5ee-41d4-af2c-48bb730696cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6eec72f2fc5a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TJSooId7gnFQ",
        "outputId": "2a6e5cc3-3d9e-4c21-94c3-281bc77f69c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bc64bb0570c0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load the pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the output layer for binary classification (Positive/Negative)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"ResNet18 model is now initialized and ready for training!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qBQZYkugf0Q",
        "outputId": "d008269e-6b61-4a93-e9c9-e6784b77946c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 74.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ResNet18 model is now initialized and ready for training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "T0UQz_RCgqEU",
        "outputId": "9791a10a-ed4f-4b16-8bae-1f96990bc5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6eec72f2fc5a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/resources/data/\"\n",
        "\n",
        "# Define transformations (resize, convert to tensor, normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Split dataset into training & validation sets (80% training, 20% validation)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"✅ Dataset loaded successfully!\")\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "W-TamqRIg6a0",
        "outputId": "d614edfe-e68a-4c2c-a3f0-2bb6cdf2cf05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/resources/data/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c85f984103e9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load dataset using ImageFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Split dataset into training & validation sets (80% training, 20% validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/resources/data/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision ibm-cos-sdk\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FvE4YIwQhXnf",
        "outputId": "64cd77e3-4080-4d84-d432-d5941f204f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting ibm-cos-sdk\n",
            "  Downloading ibm-cos-sdk-2.14.0.tar.gz (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Collecting ibm-cos-sdk-core==2.14.0 (from ibm-cos-sdk)\n",
            "  Downloading ibm-cos-sdk-core-2.14.0.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.14.0 (from ibm-cos-sdk)\n",
            "  Downloading ibm-cos-sdk-s3transfer-2.14.0.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<=1.0.1,>=0.10.0 (from ibm-cos-sdk)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.9.0 (from ibm-cos-sdk-core==2.14.0->ibm-cos-sdk)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting requests<2.32.3,>=2.32.0 (from ibm-cos-sdk-core==2.14.0->ibm-cos-sdk)\n",
            "  Downloading requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.18 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.3,>=2.32.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.3,>=2.32.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.3,>=2.32.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.14.0-py3-none-any.whl size=77232 sha256=a7481e22a7a7b1e8ee9204f4033a56ccbc56c8cd11c1400e7f8ad57f0d193533\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/01/bb/40ddcf848244c9692529698606e1f676211854f9167f508557\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.14.0-py3-none-any.whl size=661728 sha256=28dcab0bcd662e315636c9ea747f719c949bf5931d24ac53cd930e81277f98f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9a/76/f3c61ecd008692b6952e34520b4aa9323137a70ded2f25f207\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.14.0-py3-none-any.whl size=90206 sha256=dbca64284e8328bd0a976156e5aaf646096d6620da07dede60164230b05ee038\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/b4/30/eeb29a07454370efab9d445ac6bcad993ff4e61a79f910c974\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: requests, python-dateutil, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, ibm-cos-sdk-core, nvidia-cusolver-cu12, ibm-cos-sdk-s3transfer, ibm-cos-sdk\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ibm-cos-sdk-2.14.0 ibm-cos-sdk-core-2.14.0 ibm-cos-sdk-s3transfer-2.14.0 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-dateutil-2.9.0.post0 requests-2.32.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              },
              "id": "2c3633378bb54d0894b665f810850010"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision ibm-cos-sdk\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35uaziXNh-Lo",
        "outputId": "e283595f-defc-4761-ab06-805589b39e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: ibm-cos-sdk in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.14.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk) (2.14.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.14.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk) (2.14.0)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<2.32.3,>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (2.32.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.18 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.3,>=2.32.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.3,>=2.32.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.3,>=2.32.0->ibm-cos-sdk-core==2.14.0->ibm-cos-sdk) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from IBM Object Storage\n",
        "!wget -O concrete_crack_images.zip \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\"\n",
        "\n",
        "# Extract dataset into /resources/data/\n",
        "!unzip -q concrete_crack_images.zip -d /resources/data/\n",
        "\n",
        "# Verify extraction\n",
        "!ls -R /resources/data/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr-vvE09inVf",
        "outputId": "d4ae3c9b-ab7d-41c3-f4cc-0baa7084e0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-20 08:47:45--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 245259777 (234M) [application/zip]\n",
            "Saving to: ‘concrete_crack_images.zip’\n",
            "\n",
            "concrete_crack_imag 100%[===================>] 233.90M  16.6MB/s    in 15s     \n",
            "\n",
            "2025-02-20 08:48:01 (15.7 MB/s) - ‘concrete_crack_images.zip’ saved [245259777/245259777]\n",
            "\n",
            "checkdir:  cannot create extraction directory: /resources/data\n",
            "           No such file or directory\n",
            "ls: cannot access '/resources/data/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the directory manually\n",
        "!mkdir -p /resources/data\n",
        "\n",
        "# Now extract the dataset\n",
        "!unzip -q concrete_crack_images.zip -d /resources/data/\n",
        "\n",
        "# Verify extraction\n",
        "!ls -R\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ooIlwfDjRyK",
        "outputId": "be74fa65-21d7-45e3-bac2-dd44bf037faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "concrete_crack_images.zip  sample_data\n",
            "\n",
            "./sample_data:\n",
            "anscombe.json\t\t     california_housing_train.csv  mnist_train_small.csv\n",
            "california_housing_test.csv  mnist_test.csv\t\t   README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/resources/data/\"\n",
        "\n",
        "# Check folder structure\n",
        "print(\"Dataset contents:\", os.listdir(dataset_path))\n",
        "\n",
        "# Define transformations (resize, convert to tensor, normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Split dataset into training & validation sets (80% training, 20% validation)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\" Dataset loaded successfully!\")\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEvJTe4qjaXV",
        "outputId": "cd21916e-f68f-45c5-cc66-340990d5372b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contents: ['Negative', 'Positive']\n",
            " Dataset loaded successfully!\n",
            "Training samples: 32000, Validation samples: 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final layer to match our two classes (Positive/Negative)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Binary classification\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the modified model structure\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFVR39hcjjST",
        "outputId": "48ac3aa9-cf16-4721-e6f3-f6067e4ed05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-7QK2_fqfe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer (only update the final layer)\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function and optimizer initialized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i68TCWGajmCt",
        "outputId": "bcef73b3-0d07-469c-a1e9-500daeb19dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function and optimizer initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\" Training completed in {round((end_time - start_time) / 60, 2)} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRphAfuXjrML",
        "outputId": "735b0d4e-53de-4634-dbc5-eaf96d468664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.051262050388380886\n",
            "Epoch 2, Loss: 0.03221721175470157\n",
            "Epoch 3, Loss: 0.03076789655619359\n",
            " Training completed in 8.22 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "misclassified_samples = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in valid_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            if preds[i] != labels[i]:\n",
        "                misclassified_samples.append((images[i].cpu(), labels[i].cpu(), preds[i].cpu()))\n",
        "\n",
        "# Display the first 4 misclassified samples\n",
        "for i in range(min(4, len(misclassified_samples))):\n",
        "    image, true_label, predicted_label = misclassified_samples[i]\n",
        "    print(f\"Sample {i+1}: True Label = {true_label.item()}, Predicted Label = {predicted_label.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGXPIRcQmtRq",
        "outputId": "570fb296-6deb-42a2-90dc-de3c4da2c77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: True Label = 1, Predicted Label = 0\n",
            "Sample 2: True Label = 1, Predicted Label = 0\n",
            "Sample 3: True Label = 1, Predicted Label = 0\n",
            "Sample 4: True Label = 1, Predicted Label = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 5  # Adjust if needed\n",
        "epoch_losses = []  # Store loss per epoch\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_losses.append(epoch_loss)  # Save epoch loss\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"✅ Training completed in {round((end_time - start_time) / 60, 2)} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "SZSFj0D-qgub",
        "outputId": "1bfd10b9-5ff6-4c1b-ca80-19c0d9909754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a78d359079dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m     def convert(\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy on validation set\n",
        "validation_accuracy = calculate_accuracy(model, valid_loader)\n",
        "print(f\" Model Accuracy on Validation Set: {validation_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32fqmGCq1zp",
        "outputId": "11f83032-239d-4100-b0f7-205cbf3b5066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model Accuracy on Validation Set: 99.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, num_epochs + 1), epoch_losses, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "yHI9_9dErE1C",
        "outputId": "bc056390-dbd2-49ef-8f0f-dadce801ae7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (5,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c103a03f0927>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Reset the list to store loss values\n",
        "epoch_losses = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 3  # Adjust if needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_losses.append(epoch_loss)  # Store epoch loss\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\" Training completed in {round((end_time - start_time) / 60, 2)} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhWzqcokrO_2",
        "outputId": "c1a2ff5e-7025-4f61-c8a6-6d61d9604408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.023825653836742275\n",
            "Epoch 2, Loss: 0.021187976131659524\n",
            "Epoch 3, Loss: 0.026933582909474355\n",
            " Training completed in 8.27 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, num_epochs + 1), epoch_losses, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gGW5YDIHvWE1",
        "outputId": "d492e667-e1db-4f59-94c3-a31ca2d56da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy on validation set\n",
        "validation_accuracy = calculate_accuracy(model, valid_loader)\n",
        "print(f\" Model Accuracy on Validation Set: {validation_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAXgm71svkJc",
        "outputId": "3fd39b9d-b070-4fe4-9691-723e53f833c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model Accuracy on Validation Set: 99.64%\n"
          ]
        }
      ]
    }
  ]
}